
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
  <meta name="description" content="">
  <meta name="author" content="">
  <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700|PT+Serif:400,400i,700,700i|Source+Code+Pro|Source+Sans+Pro:200,200i,300,300i,400,400i,600,600i,700,700i,900,900i" rel="stylesheet">
  <link rel="icon" href="../../favicon.ico">

  <title>Top10 Netflix: a chi conviene?</title>

  <!-- Bootstrap core CSS -->
  <link href="css/bootstrap.min.css" rel="stylesheet">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <link href="css/ie10-viewport-bug-workaround.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/style.css" rel="stylesheet">

  <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
  <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
  <script src="../../assets/js/ie-emulation-modes-warning.js"></script>

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
  <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>

<body>

    <!-- Intro con titolo e immagine. Inserire immagine in /media/ con il nome cover.png
    Al posto dei segna posto aggiungere il vostro nome e matricola negli <span> -->
      <div class="intro">
        <div class="container">
          <div class="row">
            <div class="col-md-8 col-md-offset-2 text">
              <h5 class="text-center">CdLM Data Science - Esame Data Visualization - a.a. 2021/2022</h5>
              <h1 class="outlined">Top 10 settimanale di Netflix:</h1>
              <h1 class="outlined text-center">a chi conviene?</h1>
              <h4 class="text-center">Un progetto di
                <span class="name">Gaetano Chiriaco [882638]</span>,
                <span class="name">Riccardo Porcedda [886719]</span>,
                <span class="name">Gianmarco Russo [887277]</span>.
                </h5>
              </div>
          </div>
          </div>
      </div>



      <!-- Primo blocco di testo -->
      <div class="container">
        <div class="row">
          <div class="col-md-8 col-md-offset-2">
            <h6>INTRODUZIONE</h6>
            <p align="justify"> <b>Netflix</b> è una della piattaforme di streaming più utilizzate, contando oltre 214 milioni di account.
            La piattaforma si avvale di uno dei più efficaci sistemi di raccomandazioni, proponendo sulla home di ogni utente i <b>film</b> e le <b>serie TV</b>
          più popolari e conformi alle preferenze dell'abbonato.<br> Un punto in comune tra tutti gli account è la <b>"Top 10 settimanale"</b> che appare
        in cima alla homepage e che viene aggiornata ogni domenica. Milioni di persone ogni giorno vedono questa lista di dieci film o serie tv, che influenza
        invevitabilmente la scelta degli utenti. Inoltre, si tratta di una vetrina di inestimabile valore per ogni attore e regista, emergente o di successo.<br>
        Netflix calcola la <b>"Top 10 settimanale"</b> semplicemente ordinando i film o delle serie TV per ore viste negli ultimi 7 giorni in ordine decrescente.<br>
        Ma questa classifica tende effettivamente a premiare i titoli di maggiore qualità o i più popolari?
        Film e serie TV vengono trattate allo stesso modo?<br> La Top 10 è effettivamente utile agli utenti per scegliere i migliori titoli o propone prodotti di
        scarsa qualità rispetto a ciò che è nel catalogo Netflix?<br> L'obiettivo di questa ricerca è analizzare i dati relativi ad ogni film e serie TV finito in Top 10 negli ultimi sei mesi per
      rispondere a queste domande di ricerca.</p>
            <h6>DATASET UTILIZZATI</h6>
            <p align="justify"> Le seguenti visualizzazioni sono state ottenute utilizzando ed unendo due dataset indipendenti provenienti da due fonti differenti:</p>
            <ul><li><h5>Top10 Globale:</h5><p align="justify">Il dataset principale che è stato utilizzato è un insieme di dati fornito da Netflix che contiene i 10 migliori film e
              serie TV per ogni settimana. La Top 10 viene calcolata da Netflix ordinando i film per numero di ore viste. Le Top 10 settimanali contenute in questo dataset vanno dal <b>04/07/2021</b> al <b>12/12/2021</b>.
            Questo insieme di dati è stato messo a disposizione proprio da <b>Netflix</b> nel <b>Novembre 2021</b>, ed è possibile consultarlo alla pagina <a href="https://top10.netflix.com/">Netflix Top 10</a>.</p></li>

            <li><h5>Datasets IMDB:</h5><p align="justify"> Col fine di ottenere informazioni aggiuntive sui film presenti nelle Top 10 di Netflix, sono stati utilizzati diversi datasets
              forniti da <a href="https://www.imdb.com/">IMDb</a>, contenenti genere, attori, regista e molte altri attibuti su ogni titolo considerato.</p></li></ul>

            <p align="justify"> I due dataset, ottenuti attraverso <b>download</b> ed arricchiti estraendo dati utilizzando <b>API</b> e tecniche di <b>web scraping</b>, sono stati uniti tramite
              accopiando i titoli, l'anno e la tipologia (film o serie TV).<br>
              Inoltre, è proprio da questo insieme di dati che è stato ricavata la metrica di qualità, indicante la bontà di ogni prodotto su Netflix: per ogni titolo si ha un voto
             degli utenti (Rating IMDb) e dei critici (utenti verificati su <a href="https://www.rottentomatoes.com/">RottenTomatoes</a> e/o <a href="https://www.metacritic.com/">Metacritic</a>), ed assumono valori che vanno da 0 a 10.</p>

            <h6>CONFRONTO TRA ORE DI VISUALIZZAZIONE E RATING IMDb</h6>
            <p align="justify"> Il seguente <b>grafico a dispersione</b> mostra, per ogni film e Serie TV, il valore di <b>ore di visualizzazione</b> e la <b>valutazione media degli utenti</b> su IMDb. Ognuno dei titoli visualizzati è apparso almeno
            una volta nelle Top 10 di Netflix. Vi è un'evidente <b>relazione non lineare</b> tra la quantità di ore viste su Netflix e la valutazione media
            su IMDb. In media, all'aumentare dell'<b>1%</b> del numero di ore viste il voto medio aumenta di circa <b>0,67</b>.
            È inoltre fondamentale sottolineare l'evidente differenza del numero di ore di ore di visualizzazione medio fra film e serie TV, dovuto soprattutto alla maggiore durata delle serie. Ciò comporta
            che nella Top 10 le serie TV finiscono molto più facilmente ai primi posti, non perchè siano viste da più persone o siano più apprezzate, ma semplicemente per la loro maggior durata.
            Nel grafico occupante la parte alta della dashboard vengono visualizzate sia le serie TV che i film finiti in Top 10. Calcolando una linea di tendenza, si nota che al crescere del logaritmo delle ore di Visualizzazione
            aumenta la valutazione media. Tuttavia questa è una <b>correlazione a blocchi</b>, un caso di <b>falsa correlazione</b> (così come la più famosa <b>correlazione spuria</b>).
            Dividendo i due tipi di titoli, si nota come la linea di tendenza nei film sia sostanzialmente orizzontale, indicando un'assenza di correlazione tra le due variabili per questo tipo di titolo.<br>
            Le due linee orizzontali indicanti la media dei ratings dei film e le serie TV sono state calcolate considerando tutti i film e le serie TV presenti sul catalogo Netflix, non solamente i titoli finiti in Top 10.

            </p>


          </div>
        </div>
      </div>


      <!-- Prima Visualizzazione -->
      <center>
      <div class="container viz">
        <div class="row">
          <!-- Incollare qui l'embed della visualizzazione o inserire l'immagine tramite <img src="media/nomefile.jpg">
          Largezza consigliata per le immagini o per gli embed 1140px per 700px-->
          <div class='tableauPlaceholder' id='viz1643360494426' style='position: relative'><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='ItitolinellaTop10settimanalediNetflixmeritanodavvero&#47;OrevsRating' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='it-IT' /><param name='filter' value='publish=yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1643360494426');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1000px';vizElement.style.height='1177px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1000px';vizElement.style.height='1177px';} else { vizElement.style.width='100%';vizElement.style.height='1577px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>
 </div>
    </center>




<div class="container">
  <div class="row">
    <div class="col-md-8 col-md-offset-2">
      <h6>CORRELAZIONE TRA TOP 10 NETFLIX E TOP 10 SECONDO AUDIENCE E CRITICI</h6>
      <p align="justify">Per verificare se la Top 10 Netflix offra effettivamente dei contenuti di qualità ai suoi utenti è stata confrontata questa classifica
      con quella ottenuta utilizzando i voti dell'audience e dei critici. Oltre alla Top 10 settimanale di Netlix, sono state calcolate le Top 10
    settimanali per gli utenti e per la critica, ordinando i 10 titoli più visti in base al loro voto su IMDb, RottenTomatoes e Metacritic.
    Un alto valore di correlazione indica una forte similarità tra le posizioni in classifica: gli stessi film vengono messi negli stessi posti in classifica
  da Netflix, utenti e critici. Viceversa, un valore di correlazione fortemente negativo indica una forte discordanza tra la Top 10 basata sulle ore e la Top 10 basata sui
voti degli utenti o della critica. </p>
    </div>
  </div>
</div>
<center>
<div class="container viz">
  <div class="row">
    <img
    src="media/Corr2.svg"
    height="100%"
    width="100%" />

</center>

      <!-- Secondo blocco di testo -->


      <div class="container">
        <div class="row">
          <div class="col-md-8 col-md-offset-2">
            <h6>ATTORI E REGISTI: CONFRONTO TRA I TITOLI IN TOP 10 E TUTTI I TITOLI IN CARRIERA</h6>
            <p align="justify"> Nel seguente grafico a dispersione, per ogni attore o regista, viene visualizzato il voto medio di tutti i titoli della loro carriera ed il voto medio dei titoli
            nella Top 10 di Netflix. Tra tutti gli attori, vengono considerati solo coloro che hanno recitato almeno in 20 film in carriera e sono finiti in Top 10 con almeno due film differenti.
          Per gli attori dei film è interessante notare come la maggior parte si trovino al di sotto della bisettrice, indicando che sono finiti in Top 10
        con film considerati di qualità peggiore rispetto alla qualità media dei loro film.<br>
        Si può dunque affermare che <b>la maggiorparte degli attori viene pubblicizzata sulla Top10 con film di minor qualità rispetto ai loro "standard"</b>.<br>
        La situazione non è così marcata per gli attori di serie TV, anzi, in molti hanno una media maggiore su Netflix rispetto alla media generale della loro carriera.</p>
            <p align="justify"> Le conclusioni sono molto simili anche per i registi. I film che finiscono sulla top 10 di Netflix sono solitamente
              di minor qualità rispetto alle opere realizzate in carriera.</p>
          </div>
        </div>
      </div>




      <!-- Seconda Visualizzazione -->
      <center>
      <div class="container viz">
        <div class="row">
          <div class='tableauPlaceholder' id='viz1643360585428' style='position: relative'><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='AttoreoregistadifilmNetflixnonticonviene&#47;AttorieRegisti' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='it-IT' /><param name='filter' value='publish=yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1643360585428');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1000px';vizElement.style.height='677px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1000px';vizElement.style.height='677px';} else { vizElement.style.width='100%';vizElement.style.height='1327px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>
      </center>




      <!-- Quarto blocco di testo con le conlusioni-->
      <div class="container">
        <div class="row">
          <div class="col-md-8 col-md-offset-2">
            <h6>CONCLUSIONI</h6>
            <p align="justify">Ritornando alle domande che ci siamo posti all'inizio possiamo concludere che nel caso delle serie TV c'è una correlazione, seppur lenta (logaritmica), tra la qualità di queste ultime e le ore
            visualizzate, ciò non si verifica per i film.<br>
             E' inoltre importante ricordare che Netflix propone anche una classifica mista tra film e serie TV.
             Questa classifica risulta distorta a causa della maggiore durata delle serie TV, è perciò più facile che una di queste finisca in Top 10.
             A maggior supporto della tesi per cui Netflix sia più adatta alle serie TV che ai film viene incontro la terza visualizzazione,
             dove è chiaro che sia per gli attori che per i registi di film finiscono in Top 10 i titoli con voti medi al di sotto dei loro standard.
             Se lo scopo è farsi conoscere per i lavori migliori, Netflix non è dunque la piattaforma più adatta. Ma se invece lo scopo è proprio quello
             di dare popolarità ai lavori "peggiori" per trarne una forma di guadagno, allora il discorso cambia. Per questo motivo questa ricerca può essere
             considerata come una lista di consigli pratici per i professionisti del settore televisivo/cinematografico e un monito per i semplici utenti che
             vogliono iscriversi a Netflix e usufruire dei suoi contenuti.
         </p>
          </div>
        </div>
      </div>




      <div class="howTo">
        <div class="container">
          <div class="row">
            <div class="col-md-6 col-md-offset-2">

              <!-- Seguire indicazioni prof Cabitza. Aggiungere immagini con taf img se necessario-->
              <h5>Valutazione qualità</h5>
              <p align="justify">Col fine di valutare la qualità ed identificare i difetti delle visualizzazioni sono state adottate le seguenti metodologie:</p>
                <ul><li><p>La <b>valutazione euristica</b> che ha permesso di individuare le problematiche relative alla tre visualizzazioni presentate.</p></li>
                <li><p align="justify">Il <b>test utente</b> che ha permesso di valutare l’efficacia (misurando il tempo necessario per
                  eseguire un determinato compito) e l’efficienza (considerando i compiti eseguiti con
                  successo) delle tre visualizzazioni.</p></li>
                <li><p>Il <b>questionario psicometrico</b>, per verificare come gli utenti hanno percepito le visualizzazioni sotto diversi punti di vista.</p></li></ul>
              <hr>

              <h5>Valutazione euristica</h5>
              <p align="justify">La <b>valutazione euristica</b> ha coinvolto <b>tre utenti</b> ai quali è stato chiesto di interagire liberamente per
                qualche minuto con le dashboard e i grafici, commentando a voce alta il proprio operato ed il modo in cui utilizzano le visualizzazioni.
                Interpretando i comportamenti e commenti degli utenti, sono state individuate alcune problematiche
                relative ai vari grafici. Le visualizzazioni presentate ai tre utenti precendentemente si mostravano in questo modo:</p>
              <br></br>
              <ul><li><p align="center"><b>Prima visualizzazione</b>, Confronto tra ore viste e Rating IMDb.</p></ul></li>
                <img src="media/DV-eur-1.svg">
              <br></br>
              <br></br>
              <ul><li><p><b>Seconda visualizzazione</b>, correlogramma tra le tre classifiche:</p></ul></li>
                <img src="media/Corr.svg" width="90%" height="90%">
                <br></br>
                <br></br>

              <ul><li><p><b>Terza visualizzazione</b>, grafico a dispersione su attori e registi:</p></ul></li>
                <img src="media/DV-eur-3.svg">
                <br></br>
                <br></br>
              <p>Dopo aver interagito con le tre visualizzazioni, i tre utenti hanno palesato le seguenti problematiche:</p>
                <img src="media/eur.svg">
                <br></br>
                <br></br>
              <p>Le visualizzazioni riportate nella sezione principale sono le versioni finali, ottenute dopo aver applicato i consigli dati dagli utenti
                e risolto i vari <b>bug</b> (tutti gli utenti hanno riportato di non riuscire a selezionare alcuni punti nei grafici a dispersione) e problemi di <b>usabilità</b>.</p>
              <hr>

              <h5>Test Utente</h5>
              <p align="justify">Dopo aver risolto le problematiche riscontrate nella <b>valutazione euristica</b>, <b>sei
                soggetti</b> sono stati sottoposti ai <b>test utente</b>. Durante i test, <b>quattro compiti</b> (task) sono stati somministrati agli utenti; misurando
                il tempo di esecuzione del task è stata valutata l’<b>efficienza</b>, considerando il numero di task
                portati a termine è stata valutata l’<b>efficacia</b> delle visualizzazioni. Ad ogni utente è stata data la possibilità di richiedere un <b>aiuto</b> per ogni compito.
                I <b>quattro task</b> scelti sono riportati nella seguente tabella:
                <br></br>
                <img src="media/task.svg"></p>
                <br></br>
                <p align="justify">Nella tabella in basso sono riportati i secondi che ogni utente ha impiegato per completare ogni task. Le caselle in <b>verde</b> indicano che il soggetto ha
                completato il task con successo senza aiuti, le celle in <b>giallo</b> indicano che il soggetto ha completato con successso il task, ma richiedendo un aiuto. Infine, le caselle in <b>rosso</b>
                indicano che l'utente non ha risposto correttamente alle domande poste.
                <br></br>
                <img src="media/task_time.svg"></p>
                <br></br>
                <p>Nella seguente tabella è riportato il <b>tempo di completamento medio</b> e <b>mediano</b> per ogni task.
                <img src="media/task_indici.svg"></p>
                <br></br>
                <p>Infine, nel sottostante <b>violin plot</b> sono visualizzati i dati riportati nella prima tabella relativa ai test utente.
                <img src="media/task_plot.svg"></p>

                <p align="justify">Il <b>terzo</b> ed il <b>quarto task</b> sono risultati essere i compiti in media più semplici per gli utenti. Entrambi i task sono relativi alla <b>terza visualizzazione</b>. Il <b>secondo task</b>,
                che richiedeva all'utente di comprendere il <b>correlogramma</b>, è stato di gran lunga il più complesso per i sei user. Nessuno è riuscito a completarlo senza richiedere un aiuto ed è il
                task con il tempo di completamento medio e mediano più elevato.</p>
              <hr>

              <h5>Questionari psicometrici</h5>
              <p align="justify"> Il terzo ed ultimo passaggio necessario per completare le valutazioni di qualità è la creazione e la compilazione
                dei <b>questionari psicometrici</b>, utilizzati per valutare la qualità delle visualizzazioni utilizzando la <a href="https://boa.unimib.it/handle/10281/292806">Cabitza-Locoro Scale</a>.
                Questo strumento di valutazione è composto da due sezioni. Nella prima sezione l’utente deve
                valutare la qualità dell’infografica attribuendo un valore su un continuum che va da "1" (pochissimo)
                a "6" (moltissimo) per ciascuno dei seguenti aggettivi:</p>
                <ul><li><p><b>Utile</b>;</p></li>
                <li><p><b>Chiara</b>;</p></li>
                <li><p><b>Informativa</b>;</p></li>
                <li><p><b>Bella</b>;</p></li>
                <li><p><b>Intuitiva</b>.</p></li>
                </ul>
                <p align="justify">Nella seconda sezione viene richiesto all’utente di valutare, su un continuum che va da "1"
                  (bassissimo) a "6" (altissimo), il valore complessivo percepito delle visualizzazioni. Il questionario è stato somministrato
                a <b>24 utenti</b>. I risultati del questionario sono stati analizzati e riassunti tramite due tipologie di grafico: il <b>divergent stacked
                bar chart</b> e il <b>correlogramma</b>, per controllare la correlazione tra i vari aggettivi ed il valore complessivo
                della visualizzazione.  Nel <b>divergent stacked bar chart</b>, la <b>posizione</b> della "bolla" indica, tra i voti intermedi, se la proporzione dei "4" è maggiore dei "3" o viceversa. La <b>grandezza</b> della
              "bolla" indica l'incertezza relativa alla sua posizione. L'incertezza, calcolata stimando l'<b>intervallo di confidenza</b> (con un livello di confidenza pari a 0.95), è proporzionale alla <b>larghezza</b> della banda.  </p>
                <p align="justify">Nella seguente tabella sono riportati i risultati dei <b>24 test psicometrici</b> relativi alla <b>prima visualizzazione</b>
                  (scatterplot sul confronto tra ore di visualizzazione e rating IMDb):</p>
                <img src="media/psi_punteggi_1.svg">
                <img src="media/bar_viz1.svg">
                <p align="justify">Si può notare come i risultati siano molo soddisfacenti, con addirittura alcuni classi (<b>"utile"</b> e <b>"informativa"</b>)
                senza alcun negativo ("1" o "2"). La maggior parte dei valori centrali tendono verso il "4" piuttosto che il "3".</p>
                <img src="media/corr_viz1.svg">
                <p align="justify">Relativamente agli aggettivi, le maggiori correlazioni si evidenziano tra <b>"utile"</b> e <b>"informativa"</b> (0.69), <b>"chiara"</b> e
                  <b>"intuitiva"</b>(0.67) e <b>"bella"</b> e <b>"chiara"</b>(0.62). Gli aggettivi maggiormente
                  correlati al <b>valore complessivo</b> sono <b>"bella"</b> ed <b>"intuitiva"</b>. </p>

                <p align="justify"><b>Nella seconda tabella sono riportati i risultati dei <b>24 test psicometrici</b> relativi alla <b>seconda visualizzazione</b>, ovvero il correlogramma:</b></p>
                <img src="media/psi_punteggi_2.svg">
                <img src="media/bar_viz2.svg">
                <p align=justify> Per i 24 utenti, il correlogramma è risultato molto <b>informativo</b>, così come per la prima visualizzazione, ma riporta valori inferiori in
                  <b>"utile"</b> e nel <b>"valore complessivo"</b>. Sicuramente la scelta di
                questo tipo di visualizzazione crea più difficoltà ad un utente non esperto e che non conosce bene il concetto di correlazione. </p>
                <img src="media/corr_viz2.svg">
                <p align="justify"> In questo caso si evidenziano correlazioni più alte tra gli aggettivi <b>"chiara"</b> ed <b>"intuitiva"</b> (0.73),  <b>"chiara"</b> e <b>"bella"</b>(0.73)
                  ed <b>"intuitiva"</b> e <b>"bella"</b> (0.78).
                L'aggettivo maggiormente correlato al <b>"valore complessivo"</b> è <b>"intuitiva"</b>.</p>
                <p align="justify"><b> Infine, lo stesso questionario è stato utilizzato anche per la <b>terza visualizzazione</b>:</b></p>
                <img src="media/psi_punteggi_3.svg">
                <img src="media/bar_viz3.svg">
                <p align="justify"> I risultati dei test sul terzo grafico sono molto simili ai risultati del <b>primo grafico</b>, con un assenza di punteggi negativi per <b>"utile"</b> ed <b>"informativa"</b>.
                  Anche in questo caso, sui punteggi incerti ("3-4") si evidenzia una maggior proporzione di "4" rispetto ai "3".</p>
                <img src="media/corr_viz3.svg">
                <p align="justify"> Tra gli aggettivi è presente una forte correlazione tra i punteggi di <b>"chiara"</b> ed <b>"intuitiva"</b> (0.77) ed <b>"utile"</b> ed <b>"intuitiva"</b> (0.7). Inoltre,
                  si evidenzia una forte correlazione tra la <b>chiarezza</b> della visualizzazione ed il suo <b>valore complessivo</b> (0.87).</p>
              </div>






            <!-- Inserire i link di google spreadsheet/drive o i link ai file dentro la cartella data (ridotti possibilmente - max 5mb) al posto di # e dare un nome ai dataset.-->
            <div class="col-md-3 col-md-offset-1 howToSide">
            <h5>Dati utilizzati</h5>
            <p><a href="https://top10.netflix.com/">Datasets Netflix</a></p>
            <p><a href="https://datasets.imdbws.com/">Datasets IMDB</a></p>

            <!-- Inserire i link agli strumenti utilizzati per la gestione dei dati e per la visualizzazione-->
            <h5 id="tools">Strumenti utilizzati</h5>
            <p><a href="https://www.tableau.com/it-it">Tableau</a></p>
            <p><a href="https://www.python.org/">Python</a></p>
            <p><a href="https://www.rstudio.com/">R+RStudio</a></p>
            </div>
          </div>
        </div>
      </div>

    </div>
    <!-- /#page-content-wrapper -->



  <!-- Bootstrap core JavaScript
  ================================================== -->
  <!-- Placed at the end of the document so the pages load faster -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
  <script src="js/bootstrap.min.js"></script>
  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <script src="js/ie10-viewport-bug-workaround.js"></script>
  <script>$(document).ready(function () {
    var trigger = $('.hamburger'),
    overlay = $('.overlay'),
    isClosed = false;

    trigger.click(function () {
      hamburger_cross();
    });

    function hamburger_cross() {

      if (isClosed == true) {
        overlay.hide();
        trigger.removeClass('is-open');
        trigger.addClass('is-closed');
        isClosed = false;
      } else {
        overlay.show();
        trigger.removeClass('is-closed');
        trigger.addClass('is-open');
        isClosed = true;
      }
    }

    $('[data-toggle="offcanvas"]').click(function () {
      $('#wrapper').toggleClass('toggled');
    });
  });
  </script>

</body>
</html>
